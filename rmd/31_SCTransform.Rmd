---
title: "SCTransform"

output:
  html_document:
    theme: spacelab
    highlight: pygments
    code_folding: show
    toc: true
    toc_float: true
    toc_depth: 2
    df_print: paged
---


## Outline

- Setup
- Dataset
- Standard normalization
- SCTransform
- Seurat Integrate
- DGE
- SessionInfo

## Setup

```{r, setup, include=FALSE}
# .libPaths(new = "/scratch/local/rseurat/pkg-lib-4.1.3")
.libPaths()
library(formatR)
library(knitr)
library(magrittr)
knitr::opts_chunk$set(fig.width = 6, fig.height = 4, message = FALSE, warning = FALSE, tidy = TRUE, tidy.opts = list(width.cutoff = 70))
```

```{r seuratVersion,warning=FALSE,message=FALSE}
library(ggplot2)
library(Seurat)
packageVersion("Seurat")
```
## SCTransform: theory

- Default log-normalization:
  - `@counts`: read count matrix e.g. from STARsolo ("raw counts")
  - `@data`: `log1p(counts/sum(counts)*scale_factor)`
  - `@scale.data`: `scale(data, scale=TRUE, center=TRUE)`
  
- SCTransform
  - `@scale.data`: Pearson residuals from glm(raw_counts~log_umi_per_cell; error_model="NB") 
  - `@counts`: "corrected" counts back-calculated from `@scale.data` 
  - `@data`: `log1p(counts)`
  

## SCTransform: gene counts ~ total UMI per cell

It was observed that observed gene expression in a single cell RNAseq dataset is correlated with the total UMI count per cell. This holds true for different gene expression tiers (from highly to lowly expressed genes.)

![Before](images/SCTransform.F1C.png)
A single scaling factor (as in standard log-norm workflow) does not effectively normalize both lowly and highly expressed genes. Genes with different overall abundances exhibited distinct patterns after log-normalization, and only low/medium-abundance genes in the bottom three tiers were effectively normalized.
Gene variance was also confounded with sequencing depth.

In the `sctransform` approach, total UMI counts per cell are regressed out in different gene tiers, and the scaled residuals from the regression are treated as `scaled data`. A variance-stabilizing transformation is applied, too.

Some of the underlying math can be expressed as:

$$
\begin{array}{*{20}l} x_{gc} &\sim \text{NB}(\mu_{gc}, \theta_{g})\\ \ln \mu_{gc} &= \beta_{g0} + \ln n_{c}, \end{array} 
$$
After applying the transformation, the relation between the scaled residuals ("Pearson residuals") and the total UMI counts per cell is flattened out for most gene tiers. The most highly expressed genes remain difficult to normalize.

![After](images/SCTransform.F3A.png)
  Some of the advantages are:
  - improved UMAP embedding
  - reduction in FDR in differential gene expression analysis
  - improved normalization of shallow- and deep-sequenced datasets
  - improved variance estimation for lowly expressed genes
  

## SCTransform: long story short

- Requires UMIs
- One function replaces three steps in standard log-normalization workflow: normalization + regressing out nuissance variables + identifying variable features 
- Removes the effect of sequencing depth through regression
- Optional: regress other confounding variables out (e.g. perct. MT)
- Corrected counts are obtained by setting the sequencing depth for all the cells to a fixed value and reversing the learned regularized negative-binomial regression model. 


## SeuratData

We're going to work with IFNB-Stimulated and Control human PBMCs and downsample the datasets for the purpose of the excercise.


```{r SeuratData}
library(SeuratData)
ifnb <- LoadData("ifnb")
ifnb_sub <- subset(x = ifnb, downsample = 1000)
table(ifnb_sub$stim)
ifnb.list <- SplitObject(ifnb_sub, split.by = "stim")

ctrl <- ifnb.list[["CTRL"]]
stim <- ifnb.list[["STIM"]]
```

Let's remove some redundant objects from memory:

```{r cleanup}
rm(list = c("ifnb", "ifnb_sub", "ifnb.list"))
gc()
```

## Standard normalization?

Lets process the control dataset in a standard way.
We're going to save the elbow plot and compare it with the one obtained on sc-trasnformed data later on.

```{r process_noBER}
ctrl <- NormalizeData(ctrl)
ctrl <- FindVariableFeatures(ctrl, selection.method = "vst", nfeatures = 2000)
all.genes <- rownames(ctrl)
ctrl <- ScaleData(ctrl, features = all.genes)
ctrl <- RunPCA(ctrl, features = VariableFeatures(object = ctrl))
ctrl_ln <- ElbowPlot(ctrl, ndims = "30")
ctrl <- RunUMAP(ctrl, dims = 1:15)
```

## What does the data look like out of the box?

```{r out_of_the_box_umap, echo = FALSE, fig.show='hold',fig.align='center',fig.width=8,fig.height=5}
p1 <- DimPlot(ctrl, group.by = "seurat_annotations") + theme(legend.position = "bottom")
p2 <- FeaturePlot(ctrl, features = "nCount_RNA") + theme(legend.position = "right")
p1 + p2
```

> 🧭✨ Poll: [Which cell population has the highest total counts?](https://PollEv.com/multiple_choice_polls/jHulGlJWYI49AaEVkAbxm/respond) Hint: you can make use of the `FetchData` function to calculated median RNA counts per cell population. Dplyr functions `summarize` and `group_by` could be helpful to summarize a numeric variable over factor levels.


## Seurat SCTransform

The `SCTransform` function performs normalization, regressing out of nuissance variables and identification of variable features. By default, total UMI count per cell are regressed out, but it's possible to add other variables to the model, e.g. mitochondrial gene content.

We're going to use the SCTransform function with some more recent implementations of NB modelling and variance stabilizing transformation.

```{r seurat_sctransform1}
library(sctransform)
library(glmGamPoi)
ctrl <- SCTransform(ctrl, method = "glmGamPoi", vst.flavor = "v2", verbose = FALSE)
# store mitochondrial percentage in object meta data
# ctrl <- PercentageFeatureSet(ctrl, pattern = "^MT-", col.name = "percent.mt")
# ctrl <- SCTransform(ctrl, method = "glmGamPoi", vars.to.regress = "percent.mt", verbose = FALSE)
```


## Recalculate Dimensional Reductions

We have now gotten a new Assay added to the Seurat object. All we need to do now is to run PCA and UMAP for visualization in lowD.
We're also going to save the elbow plot for comparison with the log-normed dataset.

```{r sct_umap_calc}
DefaultAssay(ctrl) <- "SCT" # explain
ctrl <- RunPCA(ctrl, verbose = FALSE)
ctrl_sct <- ElbowPlot(ctrl, ndims = "30")
```

Let's compare the elbow plots for the dataset normalzed with either of the two methods:


```{r elbow_byside}
ctrl_ln + ctrl_sct
```

What has changed and what hasn't?

> 🧭✨ Poll: [What amount of standard deviation does PC1 explain after sc-transform?](https://PollEv.com/multiple_choice_polls/AQwroH3oNpZ2uQRcly2eO/respond) Hint: if you'd like to determine it numerically, you can use the `Stdev` accessor function to access the standard deviations for PC components in a Seurat object.

## Revisit UMAP

We can choose more PCs when using sctransform to calculate the lowD embedding. 
The authors believe this is because the sctransform workflow performs more effective normalization, strongly removing technical effects from the data. Higher PCs are more likely to represent subtle, but biologically relevant, sources of heterogeneity – so including them may improve downstream analysis.
We're going to use 30 top PCs to calculate the UMAP embedding in the SCT assay.

```{r sct_umap_plot, echo = FALSE, fig.show='hold',fig.align='center',fig.width=8,fig.height=5}
ctrl <- RunUMAP(ctrl, dims = 1:30, verbose = FALSE)
p1 <- DimPlot(ctrl, group.by = "seurat_annotations") + theme(legend.position = "bottom")
p2 <- FeaturePlot(ctrl, "nCount_RNA") + theme(legend.position = "right")
p1 + p2
```

What has changed and what hasn't ?

> ⌨🔥 Exercise: Apply SCTransform to the IfnB-stimulated dataset as well. 

> 🧭✨ Poll: [What amount of standard deviation does the first PC explain after applying sc-transform to the stimulated dataset?](https://PollEv.com/multiple_choice_polls/coHM0QIGIgmNdcxkYIb0i/respond)



## Prepare both datasets for integration

We're now going to revisit dataset integration after sc-transform. We can now select 3000 features for integration, instead of the default 2000 in case of log-normalized data.
SC-transformed data requires an additional preparation step prior to integration. This performs sanity checks i.e. that sctransform residuals specified in to anchor.features are present in each object of the list; subsets the scale.data slot to only contain the residuals for anchor.features.

```{r sct_stim}
stim <- SCTransform(stim, method = "glmGamPoi", vst.flavor = "v2", verbose = FALSE) %>%
  RunPCA(npcs = 30, verbose = FALSE)
ifnb.list <- list(ctrl = ctrl, stim = stim)
features <- SelectIntegrationFeatures(object.list = ifnb.list, nfeatures = 3000)
ifnb.list <- PrepSCTIntegration(object.list = ifnb.list, anchor.features = features)
```


## Seurat Integrate

The datasets are now ready for integration. The same two steps are used as for a log-transformed dataset. There is a slight difference of what the function returns, though.
If normalization.method = "LogNormalize", the integrated data is returned to the data slot and can be treated as log-normalized, corrected data.
If normalization.method = "SCT", the integrated data is returned to the scale.data slot and can be treated as centered, corrected Pearson residuals.

```{r seurat_integrate1}
immune.anchors <- FindIntegrationAnchors(
  object.list = ifnb.list, normalization.method = "SCT",
  anchor.features = features
)
immune.combined.sct <- IntegrateData(anchorset = immune.anchors, normalization.method = "SCT")
```

Let's cleanup again:

```{r cleanup2}
rm(list = c("ctrl", "stim", "ifnb.list", "features", "all.genes", "immune.anchors"))
gc()
```

## Process the newly integrated dataset

All we need to do now is to run PCA and UMAP on the integrated assay.

```{r process_integrated}
immune.combined.sct <- RunPCA(immune.combined.sct, verbose = FALSE)
immune.combined.sct <- RunUMAP(immune.combined.sct, reduction = "pca", dims = 1:30, verbose = FALSE)
```

## What does the data look like after the integration?

```{r integrated_umap, echo=FALSE,fig.show='hold',fig.align='center',fig.width=8,fig.height=5}
DimPlot(immune.combined.sct, reduction = "umap", split.by = "stim", group.by = "seurat_annotations") + theme(legend.position = "bottom")
```
It appears that both conditions are contributing to all clusters, as no condition-specific clusters are apparent. 
How would you go about checking the percentages of cells from each condition in each cluster?

## DE genes

We're now going to run DGE analysis on the SCT assay, witht he goal of getting a list of top 10 DE genes between stimulated and unstimulated B cells.
First, we're going to rename cell identities to a concatenation of celltype and condition.

As we're going to test across conditions, the datasets for which have been sc-transformed separately (multiple SCT models), we'll have to invoke `PrepSCTFindMarkers` before we can run the `FindMarkers` function. This is going to recorrect the counts in the `count` slots using minimum of the median UMI of individual objects to reverse the individual SCT regression models. `FindMarkers` is going to use the recorrected `count` slots. 

```{r sct_de}
immune.combined.sct$celltype.stim <- paste(immune.combined.sct$seurat_annotations, immune.combined.sct$stim,
  sep = "_"
)
Idents(immune.combined.sct) <- "celltype.stim"
immune.combined.sct <- PrepSCTFindMarkers(immune.combined.sct)

b.interferon.response <- FindMarkers(immune.combined.sct,
  assay = "SCT", ident.1 = "B_STIM", ident.2 = "B_CTRL",
  verbose = FALSE
)
head(b.interferon.response, n = 10)
```

> ⌨🔥 Exercise: Plot SCT "corrected counts" for one of the DE genes on a lowD representation, splitting by the stimulation status.

## Proposed solution

```{r DE_plot,fig.height=4, fig.width=8}
Idents(immune.combined.sct) <- "seurat_annotations"
inf_genes <- rownames(b.interferon.response)
DefaultAssay(immune.combined.sct) <- "SCT"
FeaturePlot(immune.combined.sct,
  features = inf_genes[1], split.by = "stim",
  cols = c("grey", "red")
) + theme(legend.position = "right")
```

## FindConservedMarkers

You may also want to identify markers that are DE between identities _independent_ of the conditions. For that purpose, you can make use of the `FindConservedMarkers` function. The `PrepSCTFindMarkers` command does not to be rerun here.


## SessionInfo

```{r sessionInfo}
sessionInfo()
```

## Citations

Hafemeister, C., Satija, R. Normalization and variance stabilization of single-cell RNA-seq data using regularized negative binomial regression. Genome Biol 20, 296 (2019). https://doi.org/10.1186/s13059-019-1874-1

Choudhary, S., Satija, R. Comparison and evaluation of statistical error models for scRNA-seq. Genome Biol 23, 27 (2022). https://doi.org/10.1186/s13059-021-02584-9

Ahlmann-Eltze C, Huber W (2020). “glmGamPoi: Fitting Gamma-Poisson Generalized Linear Models on Single Cell Count Data.” Bioinformatics. doi: 10.1093/bioinformatics/btaa1009, https://doi.org/10.1093/bioinformatics/btaa1009. 

