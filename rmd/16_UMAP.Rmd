---
title: "Cluster Visualization"
date: "`r format(Sys.time(), '%d %B, %Y')`"

output:
  bookdown::html_document2:
    number_sections: false
    global_numbering: true
    theme: spacelab
    highlight: pygments
    code_folding: show
    toc: true
    toc_float: true
    toc_depth: 2
    df_print: paged
---

# Setup

```{r setup}
# .libPaths(new = "/scratch/local/rseurat/pkg-lib-4.1.3")

suppressMessages({
  library(pheatmap)
  library(tidyverse)
  library(Seurat)
})


set.seed(8211673)

knitr::opts_chunk$set(echo = TRUE, format = TRUE, out.width = "100%")


options(parallelly.fork.enable = FALSE,
        future.globals.maxSize = 8 * 1024 ^ 2 * 1000)

plan("multicore", workers = 8)
```

```{r useful-information, echo=FALSE}
cat("work directory: ", getwd())
cat("\n")
cat("library path(s): ", .libPaths())
```

# Load Data

We'll be working with the data from Day 1 ("First steps"), let's quickly re-load and re-process again:

```{r initial, warning=FALSE}
pbmc <- Read10X(data.dir = "./datasets/filtered_gene_bc_matrices/hg19/") %>%
  CreateSeuratObject(counts = ., project = "pbmc3k", min.cells = 3, min.features = 200)

pbmc[["percent.mt"]] <- PercentageFeatureSet(pbmc, pattern = "^MT-")

pbmc <- subset(pbmc, subset = nFeature_RNA > 200 & nFeature_RNA < 2500 & percent.mt < 5)

pbmc <- NormalizeData(pbmc, verbose = FALSE)

pbmc <- FindVariableFeatures(pbmc, verbose = FALSE)

pbmc <- ScaleData(pbmc, features = rownames(pbmc), verbose = FALSE)

pbmc <- RunPCA(pbmc, features = VariableFeatures(pbmc), verbose = FALSE)

pbmc <- FindNeighbors(pbmc, dims = seq_len(10), verbose = FALSE)

pbmc <- FindClusters(pbmc, resolution = 0.5, verbose = FALSE)
```
# Heatmaps
Traditionally clusters can be shown heatmaps:

```{r heatmap, echo=FALSE}

# get cell-cluster annotations from metadata and sort
ann = pbmc@meta.data %>%  select(seurat_clusters) %>% arrange(seurat_clusters)
rn = rownames(ann)  # get cellnames (rows of ann) sorted by cluster
pc = 1:5            # select top PCA components for clarity

pbmc@reductions$pca@cell.embeddings[rn,pc] %>%           # extract CELL-PC matrix
  t() %>%                                                # transpose to PC-CELL
  pheatmap(cluster_cols = FALSE, cluster_rows = FALSE,   # don't cluster again
           show_colnames = FALSE,                        # don't show cell IDs
           annotation_col = ann,                         # colour label for columns = cells
           annotation_legend = FALSE                     # disable legend
           )
```

Notice:

- clusters were calculated in PC space, so the plot shows "PC-expression" rather than gene-expression
- clusters are based on the first 50 components (default: npcs=50), but they become increasingly less informative, so this heatmap only shows the first 5.

Ultimately we will obtain cluster-specific genes and pathways, 
but for now we will focus on how to represent cells, their neighbourhoods, and cluster assignments.

# Projections

## PCA: Principal Component Analysis

One key feature of PCA is that it amounts to a **linear** data transformation which preserves distances between all samples (here: cells) by simple rotation in a high dimensional space.
This is useful to identify informative directions and reduce noise (before clustering).
The projection on the first two components is often visualized because those correspond to the directions of maximal variation in the data. And as we might expect, the different clusters can be seen as - more or less - separating in this projection:

```{r pca, echo=FALSE}

pca <- pbmc@reductions$pca@cell.embeddings[,1:2] %>% as.data.frame()
pca$cluster <- pbmc@meta.data %>%  pull(seurat_clusters)

ggplot(pca, aes(x=PC_1, y=PC_2, color=cluster)) + geom_point()
```

There are other **non-linear** projection techniques that aim specifically to preserve distances between samples in 2 dimensions. In general this is impossible, but one can at least hope to preserve **local** distances: nearby cells in high dimension will be nearby in 2D.

[TM: figure of geographic maps and projections]

[Caption: Consider a simple geographic map that has the same goal. It also has limits and requires choices because a sphere cannot be mapped uniquely into 2D. That is why we have different projections]


For single-cell studies, two projection techniques are popular: t-SNE and UMAP


## t-SNE: t-distributed stochastic neighbor embedding
Here the key idea is to first assign distances between samples (=cells) $i$ and $j$ to probabilities

- in high dimensions:  $d_{ij} \to p_{ij}$,
- in low dimensions (2D):  $\delta_{ij} \to q_{ij}$

[illustration?]

Cells are then iteratively moved around in 2D until $q_{ij} \approx p_{ij}$.

The t- in t-SNE just corresponds to a specific choice of the map $\delta_{ij} \to q_{ij}$ which has proved useful for a wide range of applications. For further details, see some of these resources:

- [Google TechTalk](https://www.youtube.com/watch?v=RJVL80Gg3lA&list=UUtXKDgv1AVoG88PLl8nGXmw) (Duration 55 min.)
- [StatQuest!](https://www.youtube.com/watch?v=NEaUSP4YerM) video (Durantion 10 min.)
- [2019 paper](https://www.nature.com/articles/s41467-019-13056-x) summarizing the challenges for scRNA-seq data.
- [original paper](https://jmlr.csail.mit.edu/papers/volume9/vandermaaten08a/vandermaaten08a.pdf) from 2008.

The technical details may be challenging, but the execution in Seurat is straightforward.
```{r tsne}
pbmc <- RunTSNE(pbmc)
DimPlot(pbmc, reduction = "tsne")
```

Notice that there are many parameters choices (and defaults) that will affect the visualization. 
The most important are (see ?RunTSNE):

- input data (dimensionality)
- perplexity [TM: I found it quite difficult to find the default from help. Perhaps a hint is in order?]
- seed variable

> âŒ¨ðŸ”¥ Team Exercise: Find out which parameters are used per default. Explore some parameter choices together with your neighbour and observed if this will affect the plot. 

**Poll**: Is t-SNE affected by the seed variable?
[
- No. Changing seed has no affect.
- No. tSNE should always be run with seed=1
- Yes there is a noticable change.
]


```{r tsne_stochastic, eval=FALSE}
p1 <- pbmc %>% RunTSNE(seed.use = NULL) %>% DimPlot(reduction = "tsne")
p2 <- pbmc %>% RunTSNE(seed.use = NULL) %>% DimPlot(reduction = "tsne")
p1 + p2
```

**Message:** t-SNE is a stochastic algorithm!!!



## UMAP: Uniform Manifold Approximation and Projection
UMAP has a similar goal as t-SNE; but it also tries to preserve more global aspects of the data structure. It has several advantages and it is used increasingly by the single-cell community. 

Thanks to Seurat, and the underlying package ([TM: cite]), plotting UMAPs is also easy:

```{r umap, warning=FALSE}
# UMAP has no default for dims and is more verbose per default
pbmc <- RunUMAP(pbmc, dims=1:5, verbose=FALSE)
DimPlot(pbmc, reduction = "umap") 
```

> âŒ¨ðŸ”¥ Exercise:
Unsurprisingly there are again many parameters that can change the visualization.
If you have more time feel free to explore those, but for now just focus on the seed variable to initialize the stochastic algorithm

```{r umap_stochastic, eval=FALSE}
p1 <- pbmc %>% RunUMAP(dims=1:10, seed.use = NULL) %>% DimPlot(reduction = "umap")
p2 <- pbmc %>% RunUMAP(dims=1:10, seed.use = NULL) %>% DimPlot(reduction = "umap")
p1 + p2
```
**Poll**: Compared to t-SNE UMAP is more affected by the seed variable
[
- Yes. The plot is totally changed.
- No.  UMAP is less affected
- Yo.  Both tSNE and UMAP are equally sensitive. 
]


References:

- [McInnes et al. 2018](https://arxiv.org/pdf/1802.03426) --> (arxiv.org, >7500 citations!!!) 
- [Google PAIR](https://pair-code.github.io/understanding-umap/) from Google's People+AI Research (PAIR) initiative.


## Beauty Contest: t-SNE vs. UMAP

```{r contest, fig.asp=0.5}
DimPlot(pbmc, reduction = "tsne") + NoLegend() |
  DimPlot(pbmc, reduction = "umap") + NoLegend() 
  
```


## Take Away

- in contrast to PCA, both algorithms have many parameters: 
  - t-SNE: **perplexity**, ...
  - UMAP: **number of neighbors**, ...
- UMAP has several advantages: 
  - better balance between local and global structure 
  - less sensitive to seed
  - faster approximation
- global distances and orientations should not be over-interpreted
- Both algorithms aim to facilitate **visualization** - there is no ground truth! 
- Parameter exploration is allowed and encouraged - most studies just use defaults
